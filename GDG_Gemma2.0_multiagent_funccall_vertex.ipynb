{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6VgRzxiPBPOKy6Fx27wRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhkid/gdg-codelab-25/blob/main/GDG_Gemma2.0_multiagent_funccall_vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codelab: Build your first agentic AI with Gemma 2.0 and Vertex AI"
      ],
      "metadata": {
        "id": "a7gUpn3TTtrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup and Authentication"
      ],
      "metadata": {
        "id": "PSl0HXChUPla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9JbTdORvTMCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9040048-4f39-47cb-bffa-da975543dbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Required packages installed. Authenticating with Vertex AI...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies and authenticate with Vertex AI\n",
        "\n",
        "# @markdown This cell will install required packages and help you authenticate with Google Cloud.\n",
        "\n",
        "!pip install -q -U google-cloud-aiplatform\n",
        "!pip install -q matplotlib pandas numpy\n",
        "\n",
        "from google.colab import auth\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML, Markdown\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "print(\"✅ Required packages installed. Authenticating with Vertex AI...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/models/gemma-2-2b-it-1742823574849\"\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\""
      ],
      "metadata": {
        "id": "zr53hp22ym81"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Initialize Vertex AI for Gemma 2.0"
      ],
      "metadata": {
        "id": "7KS6lKbjUT0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI and Gemma 2.0\n",
        "# @markdown Configure your project and set up Gemma 2.0 via Vertex AI\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
        "\n",
        "# Set your project ID\n",
        "PROJECT_ID = \"gdg-codelab-12thMay \"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    try:\n",
        "        # Try to retrieve project ID from environment variable\n",
        "        PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "        print(f\"Using project ID from environment: {PROJECT_ID}\")\n",
        "    except:\n",
        "        print(\"❌ Please set your Google Cloud project ID\")\n",
        "\n",
        "# Set location\n",
        "LOCATION = \"asia-southeast1\"  # Vertex AI region\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Gemma 2.0 model setup\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\"  # Instruction-tuned Gemma 2.0 model\n",
        "\n",
        "try:\n",
        "    # Load the Gemma 2.0 model from Vertex AI\n",
        "    model = GenerativeModel(MODEL_NAME)\n",
        "    print(f\"✅ Successfully initialized {MODEL_NAME} on Vertex AI\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error initializing model: {e}\")\n",
        "    print(\"Please check your project configuration and model availability in Vertex AI\")\n",
        "\n",
        "# Helper function for generating responses\n",
        "\n",
        "def generate_response(prompt, temperature=0.2, max_output_tokens=1024, top_p=0.8):\n",
        "    \"\"\"Generate a response from Gemma 2.0 on Vertex AI\"\"\"\n",
        "    request_json = {\n",
        "        \"instances\": [\n",
        "            {\n",
        "                \"inputs\": prompt\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    try:\n",
        "        generation_config = GenerationConfig(\n",
        "            temperature=temperature,\n",
        "            max_output_tokens=max_output_tokens,\n",
        "            top_p=top_p\n",
        "        )\n",
        "\n",
        "        response = model.generate_content(\n",
        "            json.dumps(request\n",
        "            _json),\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"Error generating response.\"\n",
        "\n",
        "# Helper function for displaying markdown format\n",
        "\n",
        "def display_markdown(text, render_markdown=True):\n",
        "    \"\"\"\n",
        "    Display text as Markdown in a Jupyter notebook.\n",
        "\n",
        "    Args:\n",
        "        text: The text to display (can contain Markdown formatting)\n",
        "        render_markdown: If True, renders the text as Markdown.\n",
        "                        If False, displays the raw Markdown source in a code block.\n",
        "\n",
        "    Returns:\n",
        "        None: Displays the formatted content in the notebook\n",
        "    \"\"\"\n",
        "    from IPython.display import display, Markdown, HTML\n",
        "\n",
        "    if render_markdown:\n",
        "        # Display text with Markdown rendering\n",
        "        display(Markdown(text))\n",
        "    else:\n",
        "        # Display raw Markdown source code in a code block\n",
        "        display(Markdown(f\"```markdown\\n{text}\\n```\"))\n"
      ],
      "metadata": {
        "id": "vKOrujaVUj26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85572773-f299-48bf-972e-068b6fa722e1"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully initialized projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632 on Vertex AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 1: Structured Information Extraction"
      ],
      "metadata": {
        "id": "e39NwB54UpZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract structured data from text using Gemma 2.0 on Vertex AI\n",
        "\n",
        "def extract_structured_info(text, schema_description):\n",
        "    \"\"\"\n",
        "    Extract structured information from text based on a schema\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to extract information from\n",
        "        schema_description (str): Description of the schema to extract\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted structured information\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"I need to extract structured information from the following text.\n",
        "\n",
        "    Text: \"{text}\"\n",
        "\n",
        "    Please extract the following information:\n",
        "    {schema_description}\n",
        "\n",
        "    Return your answer as a markdown bullet points.\n",
        "    \"\"\"\n",
        "    response = generate_response(prompt, temperature=0.1)\n",
        "\n",
        "    # Extract JSON from response\n",
        "    return response\n",
        "\n",
        "# Example: Extract event details\n",
        "event_text = \"\"\"\n",
        "AISC 2025, organized by AITOMATIC and NIC, features a comprehensive agenda that includes a technical conference on March 12–13 at the National Convention Center in Hanoi, followed by a policy forum on March 14 at the NIC (Hoa Lac, Hanoi).\n",
        "Global figures—such as the Prime Minister of Vietnam, world-leading academics, and high-profile industry executives—will share trends, research breakthroughs, and nationwide policy perspectives on the semiconductor and AI sectors.\n",
        "Additionally, an Executive Leadership Retreat is scheduled on March 15–16 in Da Nang, providing exclusive networking opportunities, bilateral meetings, and curated activities for senior leaders and decision-makers.\n",
        "\n",
        "Among the confirmed speakers and participants are experts from corporate giants like Honeywell, Intel, AMD, and NXP, alongside forward-thinking researchers from Google DeepMind, Stanford University, and KAIST. Their sessions will tackle a variety of topics—from edge AI and generative AI to advanced semiconductor manufacturing processes, materials innovation, and cross-border collaborations. Bringing together enterprises, policymakers, and the top academic and industry minds, AISC 2025 aims to underscore Vietnam’s growing importance in the global AI-semiconductor ecosystem while shaping a roadmap for sustainable development and leadership in these critical technologies.\n",
        "Whether you’re interested in technical deep dives, networking with global pioneers, or policy-level gatherings, AISC 2025 offers a well-rounded experience. Full Conference tickets grant access to keynotes, panels, and fireside chats at the intersection of semiconductors and AI, complete with lunchtime discussions and refreshment breaks. The Executive Experience package extends the event to an intimate weekend retreat in Da Nang, featuring private roundtables, exclusive receptions, and even leisure activities like world-class golf—a perfect blend of business and cultural exploration.\n",
        "In essence, AISC 2025 stands as a multi-faceted platform that draws together top government leaders, academic scholars, and corporate trailblazers in both AI and semiconductor technology. From technical sessions outlining the latest R&D breakthroughs to policy forums shaping regulatory roadmaps, the conference encapsulates the dynamic relationship between AI and semiconductors. Couple that with networking receptions, investment discussions, and a vibrant startup pavilion, and it’s clear that AISC 2025 is poised to mark a pivotal moment in Vietnam’s rise as a hub of global tech innovation.\n",
        "\"\"\"\n",
        "\n",
        "event_schema = \"\"\"\n",
        "- event_name: The name of the event\n",
        "- date: When the event will occur\n",
        "- location: Where the event will take place\n",
        "- organizer: Who is organizing the event\n",
        "- focus_areas: Technologies or topics covered\n",
        "- ticket_info: Pricing and registration details\n",
        "- attendees: Expected number or type of attendees\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n📊 Structured Information Extraction Example:\")\n",
        "print(\"Extracting event details using Gemma 2.0 on Vertex AI...\\n\")\n",
        "\n",
        "event_details = extract_structured_info(event_text, event_schema)\n",
        "\n",
        "print(\"Extracted Event Details:\")\n",
        "#print(json.dumps(event_details, indent=2))\n",
        "print(display_markdown(event_details))"
      ],
      "metadata": {
        "id": "vCqZFPVfUyoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "eaf013c6-2df0-4a79-c9cf-407ed04dd30f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Structured Information Extraction Example:\n",
            "Extracting event details using Gemma 2.0 on Vertex AI...\n",
            "\n",
            "Extracted Event Details:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's the extracted information in markdown bullet points:\n\n- **event_name:** AISC 2025\n- **date:** March 12-13, March 14, March 15-16, 2025\n- **location:** National Convention Center in Hanoi, Vietnam; Da Nang, Vietnam\n- **organizer:** AITOMATIC and NIC\n- **focus_areas:** \n    - Semiconductor and AI sectors\n    - Edge AI\n    - Generative AI\n    - Advanced semiconductor manufacturing processes\n    - Materials innovation\n    - Cross-border collaborations\n- **ticket_info:** \n    - Full Conference tickets grant access to keynotes, panels, fireside chats, lunchtime discussions, and refreshment breaks.\n    - Executive Experience package includes an intimate weekend retreat with private roundtables, exclusive receptions, and leisure activities like world-class golf.\n- **attendees:** \n    - Global figures (Prime Minister of Vietnam, world-leading academics, high-profile industry executives)\n    - Experts from corporate giants (Honeywell, Intel, AMD, NXP)\n    - Researchers from Google DeepMind, Stanford University, and KAIST\n    - Senior leaders and decision-makers \n    - Startups \n    - Policymakers \n    - Government leaders \n    - Academic scholars \n    - Corporate trailblazers in AI and semiconductor technology \n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 2: Multi-agent Research System powered by Gemma 2.0"
      ],
      "metadata": {
        "id": "QBEdmIV8U5rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Build a simple multi-agent research system using Gemma 2.0 on Vertex AI\n",
        "\n",
        "class ResearchAgent:\n",
        "    \"\"\"\n",
        "    A multi-agent system for research powered by Gemma 2.0 on Vertex AI\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, debug=False):\n",
        "        self.model = model\n",
        "        self.debug = debug\n",
        "        self.agents = {\n",
        "            \"planner\": self._planning_agent,\n",
        "            \"researcher\": self._research_agent,\n",
        "            \"analyzer\": self._analysis_agent,\n",
        "            \"reporter\": self._report_agent  # This matches the function name below\n",
        "        }\n",
        "\n",
        "    def _planning_agent(self, query):\n",
        "        \"\"\"Plan the research strategy\"\"\"\n",
        "        prompt = f\"\"\"You are a research planning specialist.\n",
        "\n",
        "Given the research query: \"{query}\"\n",
        "\n",
        "Create a detailed research plan with the following components:\n",
        "1. Key questions to answer\n",
        "2. Necessary data points to collect\n",
        "3. Analysis methods to apply\n",
        "4. Structure for the final report\n",
        "\n",
        "Return a structured, step-by-step plan.\n",
        "\"\"\"\n",
        "        return generate_response(prompt, temperature=0.2)\n",
        "\n",
        "    def _research_agent(self, query, plan):\n",
        "        \"\"\"Gather information based on the research plan\"\"\"\n",
        "        # Ensure plan is treated as a string\n",
        "        plan_text = plan if isinstance(plan, str) else str(plan)\n",
        "\n",
        "        prompt = f\"\"\"You are a thorough research specialist.\n",
        "\n",
        "Research query: \"{query}\"\n",
        "\n",
        "Research plan:\n",
        "{plan_text}\n",
        "\n",
        "Simulate the research data collection process and provide:\n",
        "1. Key facts and data points you would gather\n",
        "2. Sources you would consult (simulated)\n",
        "3. Any challenges in data collection\n",
        "4. Preliminary observations from the collected data\n",
        "\n",
        "Present this as a research notes document.\n",
        "\"\"\"\n",
        "        return generate_response(prompt, temperature=0.3)\n",
        "\n",
        "    def _analysis_agent(self, research_notes):\n",
        "        \"\"\"Analyze the gathered information\"\"\"\n",
        "        # Ensure research_notes is treated as a string\n",
        "        notes_text = research_notes if isinstance(research_notes, str) else str(research_notes)\n",
        "\n",
        "        prompt = f\"\"\"You are a data analysis specialist.\n",
        "\n",
        "Research notes:\n",
        "{notes_text}\n",
        "\n",
        "Provide a comprehensive analysis including:\n",
        "1. Key patterns and trends\n",
        "2. Notable correlations\n",
        "3. Potential causalities\n",
        "4. Gaps requiring further research\n",
        "5. Statistical observations (simulated)\n",
        "\n",
        "Present this as an analytical summary.\n",
        "\"\"\"\n",
        "        return generate_response(prompt, temperature=0.2)\n",
        "\n",
        "    def _report_agent(self, query, plan, research_notes, analysis):\n",
        "        \"\"\"Generate a final research report\"\"\"\n",
        "        # Ensure all inputs are treated as strings\n",
        "        plan_text = plan if isinstance(plan, str) else str(plan)\n",
        "        notes_text = research_notes if isinstance(research_notes, str) else str(research_notes)\n",
        "        analysis_text = analysis if isinstance(analysis, str) else str(analysis)\n",
        "\n",
        "        # Safely extract first 500 chars for truncated sections\n",
        "        notes_truncated = notes_text[:500] if len(notes_text) > 500 else notes_text\n",
        "        analysis_truncated = analysis_text[:500] if len(analysis_text) > 500 else analysis_text\n",
        "\n",
        "        prompt = f\"\"\"You are a professional report writer.\n",
        "\n",
        "Original query: \"{query}\"\n",
        "\n",
        "Research plan:\n",
        "{plan_text}\n",
        "\n",
        "Research notes:\n",
        "{notes_truncated}... [notes truncated]\n",
        "\n",
        "Analysis:\n",
        "{analysis_truncated}... [analysis truncated]\n",
        "\n",
        "Create a well-structured, professional research report with:\n",
        "1. Executive summary\n",
        "2. Introduction and background\n",
        "3. Methodology\n",
        "4. Key findings\n",
        "5. Discussion of implications\n",
        "6. Conclusions and recommendations\n",
        "7. Appendix (simulated references)\n",
        "\n",
        "The report should be comprehensive yet concise.\n",
        "\"\"\"\n",
        "        return generate_response(prompt, temperature=0.2, max_output_tokens=2048)\n",
        "\n",
        "    def execute_research(self, query):\n",
        "        \"\"\"Execute the full research pipeline\"\"\"\n",
        "        if self.debug:\n",
        "            print(\"📋 Starting research process...\")\n",
        "\n",
        "        # Step 1: Planning\n",
        "        if self.debug:\n",
        "            print(\"🧩 Planning research approach...\")\n",
        "        plan = self.agents[\"planner\"](query)\n",
        "        if self.debug:\n",
        "            print(\"✅ Research plan created\")\n",
        "\n",
        "        # Step 2: Research\n",
        "        if self.debug:\n",
        "            print(\"🔍 Gathering research data...\")\n",
        "        try:\n",
        "            research_notes = self.agents[\"researcher\"](query, plan)\n",
        "            if self.debug:\n",
        "                print(\"✅ Research data collected\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in research phase: {e}\")\n",
        "            research_notes = \"Unable to collect research data due to an error.\"\n",
        "\n",
        "        # Step 3: Analysis\n",
        "        if self.debug:\n",
        "            print(\"📊 Analyzing research data...\")\n",
        "        try:\n",
        "            analysis = self.agents[\"analyzer\"](research_notes)\n",
        "            if self.debug:\n",
        "                print(\"✅ Analysis complete\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in analysis phase: {e}\")\n",
        "            analysis = \"Unable to complete analysis due to an error.\"\n",
        "\n",
        "        # Step 4: Reporting\n",
        "        if self.debug:\n",
        "            print(\"📝 Generating final report...\")\n",
        "        try:\n",
        "            # Use \"reporter\" to match the key in self.agents dictionary\n",
        "            report = self.agents[\"reporter\"](query, plan, research_notes, analysis)\n",
        "            if self.debug:\n",
        "                print(\"✅ Report generated\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in reporting phase: {e}\")\n",
        "            report = \"Unable to generate report due to an error.\"\n",
        "\n",
        "        # Return the complete research package\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"plan\": plan,\n",
        "            \"research_notes\": research_notes,\n",
        "            \"analysis\": analysis,\n",
        "            \"report\": report\n",
        "        }\n",
        "\n",
        "# Create a research agent\n",
        "research_system = ResearchAgent(model, debug=True)\n",
        "\n",
        "# Execute a research task\n",
        "research_query = \"What are the current trends and challenges in EV charging infrastructure in smart cities?\"\n",
        "\n",
        "print(\"\\n🔬 Multi-agent Research System Example:\")\n",
        "print(f\"Executing research on: '{research_query}'\\n\")\n",
        "\n",
        "research_results = research_system.execute_research(research_query)\n",
        "\n",
        "# Display the final report\n",
        "print(\"\\n📑 Final Research Report:\")\n",
        "display_markdown(research_results[\"report\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "xb3n3TMuwcK2",
        "outputId": "b6787639-1bad-4bb2-ccc1-312671841c46"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔬 Multi-agent Research System Example:\n",
            "Executing research on: 'What are the current trends and challenges in EV charging infrastructure in smart cities?'\n",
            "\n",
            "📋 Starting research process...\n",
            "🧩 Planning research approach...\n",
            "✅ Research plan created\n",
            "🔍 Gathering research data...\n",
            "✅ Research data collected\n",
            "📊 Analyzing research data...\n",
            "Error generating response: 'str' object has no attribute 'get'\n",
            "✅ Analysis complete\n",
            "📝 Generating final report...\n",
            "Error generating response: 'str' object has no attribute 'get'\n",
            "✅ Report generated\n",
            "\n",
            "📑 Final Research Report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Error generating response."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI and Gemma 2.0\n",
        "import os\n",
        "import json\n",
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set your project ID\n",
        "PROJECT_ID = \"gdg-codelab-12thMay\"\n",
        "LOCATION = \"asia-southeast1\"  # Vertex AI region\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Gemma 2.0 model setup\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\"\n",
        "\n",
        "def generate_response(prompt):\n",
        "    \"\"\"Generate a response from Gemma 2.0 on Vertex AI with minimal processing\"\"\"\n",
        "    try:\n",
        "        # Call the endpoint with minimal parameters\n",
        "        endpoint = aiplatform.Endpoint(MODEL_NAME)\n",
        "        response = endpoint.predict(\n",
        "            instances=[{\"inputs\": prompt}]\n",
        "        )\n",
        "\n",
        "        # Extract just the text content\n",
        "        text_content = response.predictions[0]\n",
        "        print(f\"Successfully generated response of length: {len(text_content)}\")\n",
        "        return text_content\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error generating response: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "\n",
        "class ResearchAgent:\n",
        "    \"\"\"\n",
        "    A multi-agent research system\n",
        "    \"\"\"\n",
        "\n",
        "    def execute_research(self, query):\n",
        "        \"\"\"Execute the full research pipeline with minimal complexity\"\"\"\n",
        "        print(\"📋 Starting research process...\")\n",
        "\n",
        "        # Step 1: Planning\n",
        "        print(\"🧩 Planning research approach...\")\n",
        "        plan_prompt = f\"\"\"You are a research planning specialist.\n",
        "        Given the research query: \"{query}\"\n",
        "        Create a detailed research plan with key questions, data points, analysis methods, and report structure.\"\"\"\n",
        "        plan = generate_response(plan_prompt)\n",
        "        print(\"✅ Research plan created\")\n",
        "\n",
        "        # Step 2: Research - most likely source of the error\n",
        "        print(\"🔍 Gathering research data...\")\n",
        "        research_prompt = f\"\"\"You are a research specialist. Research this query: \"{query}\".\n",
        "        Provide key facts and simulated data points.\"\"\"\n",
        "        research_notes = generate_response(research_prompt)\n",
        "        print(\"✅ Research data collected\")\n",
        "\n",
        "        # Step 3: Analysis\n",
        "        print(\"📊 Analyzing research data...\")\n",
        "        analysis_prompt = f\"\"\"You are a data analysis specialist. Analyze this topic: \"{query}\".\n",
        "        Provide key patterns, correlations, and insights.\"\"\"\n",
        "        analysis = generate_response(analysis_prompt)\n",
        "        print(\"✅ Analysis complete\")\n",
        "\n",
        "        # Step 4: Reporting\n",
        "        print(\"📝 Generating final report...\")\n",
        "        report_prompt = f\"\"\"You are a professional report writer.\n",
        "        Create a comprehensive research report on: \"{query}\".\n",
        "        Include executive summary, introduction, methodology, findings, discussion, and conclusion.\"\"\"\n",
        "        report = generate_response(report_prompt)\n",
        "        print(\"✅ Report generated\")\n",
        "\n",
        "        # Return everything\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"plan\": plan,\n",
        "            \"research_notes\": research_notes,\n",
        "            \"analysis\": analysis,\n",
        "            \"report\": report\n",
        "        }\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# Create the research agent\n",
        "research_system = ResearchAgent()\n",
        "\n",
        "# Execute a research task\n",
        "research_query = \"What are the current trends and challenges in EV charging infrastructure in smart cities?\"\n",
        "\n",
        "print(\"\\n🔬 Multi-agent Research System Example:\")\n",
        "print(f\"Executing research on: '{research_query}'\\n\")\n",
        "\n",
        "research_results = research_system.execute_research(research_query)\n",
        "\n",
        "# Display the final report with markdown formatting\n",
        "print(\"\\n📑 Final Research Report:\")\n",
        "display(Markdown(research_results[\"report\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Yk3T7GHwmMK",
        "outputId": "be50edf9-55f9-4a4e-f0bd-9f093a938db2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔬 Multi-agent Research System Example:\n",
            "Executing research on: 'What are the current trends and challenges in EV charging infrastructure in smart cities?'\n",
            "\n",
            "📋 Starting research process...\n",
            "🧩 Planning research approach...\n",
            "Successfully generated response of length: 4552\n",
            "✅ Research plan created\n",
            "🔍 Gathering research data...\n",
            "Successfully generated response of length: 4074\n",
            "✅ Research data collected\n",
            "📊 Analyzing research data...\n",
            "Successfully generated response of length: 5689\n",
            "✅ Analysis complete\n",
            "📝 Generating final report...\n",
            "Successfully generated response of length: 4067\n",
            "✅ Report generated\n",
            "\n",
            "📑 Final Research Report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n**Executive Summary:**\n\nSmart cities are increasingly integrating electric vehicles (EVs) into their transportation systems, driving the demand for robust and convenient EV charging infrastructure. This report analyzes the current trends and challenges in EV charging infrastructure development within smart cities. The findings reveal that the adoption of wireless charging, advanced metering infrastructure, and smart payment systems have significantly improved the user experience and operational efficiency. However, the high cost of installation, lack of standardized regulations, and limited public awareness remain significant challenges. \n\n**Introduction:**\n\nThe global transition towards sustainable transportation is accelerating, with electric vehicles (EVs) playing a key role. Smart cities, leveraging technology to enhance citizen well-being, are expected to play a crucial role in this transition. EV charging infrastructure is essential for the widespread adoption of EVs in smart cities. \n\n**Methodology:**\n\nThis report employs a combination of desk research and expert interviews. Desk research involved studying relevant academic papers, industry reports, and government data on EV charging infrastructure in smart cities. Expert interviews were conducted with industry experts, including EV charging infrastructure developers, policymakers, and urban planners.\n\n**Findings:**\n\n* **Adoption of Advanced Technologies:**  Smart charging stations are becoming increasingly common. These stations offer features such as wireless charging, dynamic pricing, and remote monitoring, improving user experience and efficiency.\n* **Increased Public-Private Partnership:** Public-private partnerships are playing a significant role in developing and deploying EV charging infrastructure in smart cities.\n* **Focus on Sustainability:**  Smart charging systems are being designed to integrate renewable energy sources and optimize charging times to minimize environmental impact.\n* **Standardization Challenges:** There are still significant challenges in establishing industry standards and regulations for EV charging infrastructure.\n* **Limited Public Awareness:**  Lack of public awareness about available charging options and the benefits of EVs is hindering EV adoption in some smart cities.\n\n**Discussion:**\n\nThe integration of EV charging infrastructure into smart city ecosystems is crucial for successful EV adoption. The adoption of advanced technologies like wireless charging and smart grid integration is driving user experience and operational efficiency improvements. However, challenges remain in addressing the high cost of installation, the lack of standardized regulations, and limited public awareness.\n\n**Conclusion:**\n\nThe development of comprehensive and efficient EV charging infrastructure is vital for smart cities to achieve their sustainability goals. While emerging trends and partnerships offer promising solutions, overcoming the identified challenges through policy reforms and public engagement is crucial for fostering a smooth transition to a sustainable transportation future.\n\n**Recommendations:**\n\n* Governments should prioritize the development of clear and standardized regulations for EV charging infrastructure.\n* Public-private partnerships should be further incentivized to accelerate the deployment of charging stations.\n* Initiatives to increase public awareness about EVs and the benefits of charging infrastructure should be implemented.\n* Research and development efforts should focus on developing cost-effective and sustainable charging technologies.\n* Smart city platforms should be further integrated to optimize charging operations and promote user-friendly services.\n\n\n**Appendix:**\n\n* List of interviewees\n* Relevant research papers and reports\n* Government data and policy documents\n\n\n\n**Note:** This report is a structured framework. You can expand on any section, adding further details, specific case studies, and relevant statistics to create a more comprehensive and informative research report. \n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaBaq6tQ96h9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}